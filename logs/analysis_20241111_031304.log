2024-11-11 03:13:04,457 - root - INFO - open_end.py:20 - __init__ - Initializing OpenEndedAnalysis
2024-11-11 03:13:04,457 - root - DEBUG - open_end.py:42 - _download_nltk_data - Checking/Downloading NLTK package: punkt
2024-11-11 03:13:04,652 - root - DEBUG - open_end.py:42 - _download_nltk_data - Checking/Downloading NLTK package: stopwords
2024-11-11 03:13:04,653 - root - DEBUG - open_end.py:42 - _download_nltk_data - Checking/Downloading NLTK package: averaged_perceptron_tagger
2024-11-11 03:13:04,660 - root - DEBUG - open_end.py:42 - _download_nltk_data - Checking/Downloading NLTK package: wordnet
2024-11-11 03:13:04,682 - root - WARNING - open_end.py:52 - _download_nltk_data - Punkt tokenizer not found, downloading additional resources...
2024-11-11 03:13:04,682 - root - INFO - open_end.py:55 - _download_nltk_data - All required NLTK packages downloaded successfully
2024-11-11 03:13:04,683 - root - INFO - open_end.py:23 - __init__ - Initialization complete
2024-11-11 03:13:04,683 - root - INFO - open_end.py:72 - quantify_responses - Processing 4 responses
2024-11-11 03:13:04,683 - root - DEBUG - open_end.py:76 - quantify_responses - Processing response: 'Fake news is misinformation spread on social media.'
2024-11-11 03:13:04,683 - root - DEBUG - open_end.py:90 - quantify_responses - Coding result for response: {'misinformation': 1, 'intentionally deceptive': 0, 'platform': 1, 'purpose': 0}
2024-11-11 03:13:04,683 - root - DEBUG - open_end.py:76 - quantify_responses - Processing response: 'Fake news is news that is intentionally deceptive.'
2024-11-11 03:13:04,683 - root - DEBUG - open_end.py:90 - quantify_responses - Coding result for response: {'misinformation': 1, 'intentionally deceptive': 1, 'platform': 0, 'purpose': 0}
2024-11-11 03:13:04,683 - root - DEBUG - open_end.py:76 - quantify_responses - Processing response: 'I think fake news is a lie that people share to create chaos.'
2024-11-11 03:13:04,683 - root - DEBUG - open_end.py:90 - quantify_responses - Coding result for response: {'misinformation': 1, 'intentionally deceptive': 0, 'platform': 0, 'purpose': 1}
2024-11-11 03:13:04,683 - root - DEBUG - open_end.py:76 - quantify_responses - Processing response: 'False stories that are made up to mislead the public.'
2024-11-11 03:13:04,683 - root - DEBUG - open_end.py:90 - quantify_responses - Coding result for response: {'misinformation': 1, 'intentionally deceptive': 0, 'platform': 0, 'purpose': 1}
2024-11-11 03:13:04,685 - root - INFO - open_end.py:94 - quantify_responses - Response coding completed successfully
2024-11-11 03:13:04,690 - root - INFO - open_end.py:112 - quantify_verification_steps - Quantifying verification steps
2024-11-11 03:13:04,690 - root - DEBUG - open_end.py:116 - quantify_verification_steps - Processing response for verification steps: 'I cross-check the information with reliable news sources.'
2024-11-11 03:13:04,691 - root - ERROR - open_end.py:129 - quantify_verification_steps - Error in quantifying verification steps: 
**********************************************************************
  Resource [93mpunkt_tab[0m not found.
  Please use the NLTK Downloader to obtain the resource:

  [31m>>> import nltk
  >>> nltk.download('punkt_tab')
  [0m
  For more information see: https://www.nltk.org/data.html

  Attempted to load [93mtokenizers/punkt_tab/english/[0m

  Searched in:
    - '/Users/luciusjmorningstar/nltk_data'
    - '/Users/luciusjmorningstar/Documents/GitHub/Ai-Interaction-Scripts/venv/nltk_data'
    - '/Users/luciusjmorningstar/Documents/GitHub/Ai-Interaction-Scripts/venv/share/nltk_data'
    - '/Users/luciusjmorningstar/Documents/GitHub/Ai-Interaction-Scripts/venv/lib/nltk_data'
    - '/usr/share/nltk_data'
    - '/usr/local/share/nltk_data'
    - '/usr/lib/nltk_data'
    - '/usr/local/lib/nltk_data'
**********************************************************************
Traceback (most recent call last):
  File "/Users/luciusjmorningstar/Documents/GitHub/Ai-Interaction-Scripts/scripts/polyPsych/open_end.py", line 121, in quantify_verification_steps
    steps = len(sent_tokenize(str(response)))
                ~~~~~~~~~~~~~^^^^^^^^^^^^^^^
  File "/Users/luciusjmorningstar/Documents/GitHub/Ai-Interaction-Scripts/venv/lib/python3.13/site-packages/nltk/tokenize/__init__.py", line 119, in sent_tokenize
    tokenizer = _get_punkt_tokenizer(language)
  File "/Users/luciusjmorningstar/Documents/GitHub/Ai-Interaction-Scripts/venv/lib/python3.13/site-packages/nltk/tokenize/__init__.py", line 105, in _get_punkt_tokenizer
    return PunktTokenizer(language)
  File "/Users/luciusjmorningstar/Documents/GitHub/Ai-Interaction-Scripts/venv/lib/python3.13/site-packages/nltk/tokenize/punkt.py", line 1744, in __init__
    self.load_lang(lang)
    ~~~~~~~~~~~~~~^^^^^^
  File "/Users/luciusjmorningstar/Documents/GitHub/Ai-Interaction-Scripts/venv/lib/python3.13/site-packages/nltk/tokenize/punkt.py", line 1749, in load_lang
    lang_dir = find(f"tokenizers/punkt_tab/{lang}/")
  File "/Users/luciusjmorningstar/Documents/GitHub/Ai-Interaction-Scripts/venv/lib/python3.13/site-packages/nltk/data.py", line 579, in find
    raise LookupError(resource_not_found)
LookupError: 
**********************************************************************
  Resource [93mpunkt_tab[0m not found.
  Please use the NLTK Downloader to obtain the resource:

  [31m>>> import nltk
  >>> nltk.download('punkt_tab')
  [0m
  For more information see: https://www.nltk.org/data.html

  Attempted to load [93mtokenizers/punkt_tab/english/[0m

  Searched in:
    - '/Users/luciusjmorningstar/nltk_data'
    - '/Users/luciusjmorningstar/Documents/GitHub/Ai-Interaction-Scripts/venv/nltk_data'
    - '/Users/luciusjmorningstar/Documents/GitHub/Ai-Interaction-Scripts/venv/share/nltk_data'
    - '/Users/luciusjmorningstar/Documents/GitHub/Ai-Interaction-Scripts/venv/lib/nltk_data'
    - '/usr/share/nltk_data'
    - '/usr/local/share/nltk_data'
    - '/usr/lib/nltk_data'
    - '/usr/local/lib/nltk_data'
**********************************************************************

2024-11-11 03:13:04,693 - root - CRITICAL - open_end.py:216 - <module> - Application failed: 
**********************************************************************
  Resource [93mpunkt_tab[0m not found.
  Please use the NLTK Downloader to obtain the resource:

  [31m>>> import nltk
  >>> nltk.download('punkt_tab')
  [0m
  For more information see: https://www.nltk.org/data.html

  Attempted to load [93mtokenizers/punkt_tab/english/[0m

  Searched in:
    - '/Users/luciusjmorningstar/nltk_data'
    - '/Users/luciusjmorningstar/Documents/GitHub/Ai-Interaction-Scripts/venv/nltk_data'
    - '/Users/luciusjmorningstar/Documents/GitHub/Ai-Interaction-Scripts/venv/share/nltk_data'
    - '/Users/luciusjmorningstar/Documents/GitHub/Ai-Interaction-Scripts/venv/lib/nltk_data'
    - '/usr/share/nltk_data'
    - '/usr/local/share/nltk_data'
    - '/usr/lib/nltk_data'
    - '/usr/local/lib/nltk_data'
**********************************************************************
Traceback (most recent call last):
  File "/Users/luciusjmorningstar/Documents/GitHub/Ai-Interaction-Scripts/scripts/polyPsych/open_end.py", line 206, in <module>
    steps = analyzer.quantify_verification_steps(responses_verification)
  File "/Users/luciusjmorningstar/Documents/GitHub/Ai-Interaction-Scripts/scripts/polyPsych/open_end.py", line 121, in quantify_verification_steps
    steps = len(sent_tokenize(str(response)))
                ~~~~~~~~~~~~~^^^^^^^^^^^^^^^
  File "/Users/luciusjmorningstar/Documents/GitHub/Ai-Interaction-Scripts/venv/lib/python3.13/site-packages/nltk/tokenize/__init__.py", line 119, in sent_tokenize
    tokenizer = _get_punkt_tokenizer(language)
  File "/Users/luciusjmorningstar/Documents/GitHub/Ai-Interaction-Scripts/venv/lib/python3.13/site-packages/nltk/tokenize/__init__.py", line 105, in _get_punkt_tokenizer
    return PunktTokenizer(language)
  File "/Users/luciusjmorningstar/Documents/GitHub/Ai-Interaction-Scripts/venv/lib/python3.13/site-packages/nltk/tokenize/punkt.py", line 1744, in __init__
    self.load_lang(lang)
    ~~~~~~~~~~~~~~^^^^^^
  File "/Users/luciusjmorningstar/Documents/GitHub/Ai-Interaction-Scripts/venv/lib/python3.13/site-packages/nltk/tokenize/punkt.py", line 1749, in load_lang
    lang_dir = find(f"tokenizers/punkt_tab/{lang}/")
  File "/Users/luciusjmorningstar/Documents/GitHub/Ai-Interaction-Scripts/venv/lib/python3.13/site-packages/nltk/data.py", line 579, in find
    raise LookupError(resource_not_found)
LookupError: 
**********************************************************************
  Resource [93mpunkt_tab[0m not found.
  Please use the NLTK Downloader to obtain the resource:

  [31m>>> import nltk
  >>> nltk.download('punkt_tab')
  [0m
  For more information see: https://www.nltk.org/data.html

  Attempted to load [93mtokenizers/punkt_tab/english/[0m

  Searched in:
    - '/Users/luciusjmorningstar/nltk_data'
    - '/Users/luciusjmorningstar/Documents/GitHub/Ai-Interaction-Scripts/venv/nltk_data'
    - '/Users/luciusjmorningstar/Documents/GitHub/Ai-Interaction-Scripts/venv/share/nltk_data'
    - '/Users/luciusjmorningstar/Documents/GitHub/Ai-Interaction-Scripts/venv/lib/nltk_data'
    - '/usr/share/nltk_data'
    - '/usr/local/share/nltk_data'
    - '/usr/lib/nltk_data'
    - '/usr/local/lib/nltk_data'
**********************************************************************

